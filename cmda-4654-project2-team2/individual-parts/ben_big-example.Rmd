---
title: "Boosted Trees"
subtitle: "Project 2, by Group 2"
author: "CMDA 4654"
date: "`r Sys.Date()`"
output:
  xaringan::moon_reader:
    css: [default, metropolis, metropolis-fonts]
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false

---
```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE,
        show.signif.stars = FALSE) 
```


# Big Example (Economic Freedom)

The following dataset is used to determine the freedom index and was published in the *Economic Freedom of the World* by the *Fraser Institute* measures the degree to which the policies and istitutions of countries are supportive of economic freedom. There are 36 variables in this data set but each of them fit into a one of the five broad areas.

**1.** Size of Goverment

**2.** Legal System and Property Rights

**3.** Sound Money

**4.** Freedom to Trade Internatioanlly

**5.** Regulation

- Dataset: https://www.kaggle.com/gsutters/economic-freedom

---

#Economic Freedom (Read and split)

```{r,warning=FALSE,message=FALSE}
library(gbm)
library(rsample)
library(dplyr)
library(caret)
```
These are the required packages needed to run gradient boosting machines.

```{r,echo=FALSE}
freedom <- read.csv("C:/Users/benny/OneDrive/Documents/CMDA 4654/economic-freedom/efw_cc.csv", header = T)
freedom <- freedom[!is.na(freedom$ECONOMIC.FREEDOM),]

```

---

#Economic Freedom (Initial Model)
```{r}
free_split <- initial_split(freedom, prop = .7)
free_train <- training(free_split)
free_test  <- testing(free_split)
gbm.fit <- gbm(formula = ECONOMIC.FREEDOM ~ ., distribution = "gaussian", 
               data = free_train, n.trees = 5000, interaction.depth = 1, 
               shrinkage = 0.001, cv.folds = 5)
gbm.fit
```

If you wanted to use gradient boosting for classification, all you need to do to implement it is to change the distribution to bernoulli and to make sure your response variable is a column that represents some sort of classification and contains either ones or zeros.

---
#Economic Freedom (Initial Model cont.)
.pull-left[
```{r, eval=FALSE}
fit_sum1 <- summary(gbm.fit)
```
```{r, echo=FALSE}
fit_sum1 <- summary(gbm.fit)
title("Variable Relevance")
```
]
.pull-right[
```{r}
head(data.frame(fit_sum1$var, 
                fit_sum1$rel.inf),10)

```
]
---

#Economic Freedom (MSE and Min Trees)
.pull-left[
```{r highlight.output = TRUE}
sqrt(min(gbm.fit$cv.error))
```
]

.pull-right[
```{r, eval=FALSE}
gbm.perf(gbm.fit, method = "cv")
```
```{r, echo=FALSE, highlight.output = TRUE}
gbm.perf(gbm.fit, method = "cv")
title("GBM Preformance")
```
]
---

#Economic Freedom (Second Model)
```{r}
gbm.fit2 <- gbm(formula = ECONOMIC.FREEDOM ~ ., distribution = "gaussian", 
                data = free_train, n.trees = 2500, interaction.depth = 1, 
                shrinkage = 0.001, cv.folds = 5) 
min_MSE <- which.min(gbm.fit2$cv.error)
min_MSE
```
```{r, highlight.output = TRUE}
# get MSE and compute RMSE
sqrt(gbm.fit2$cv.error[min_MSE])
```
---

#Economic Freedom (Min Trees)
```{r, eval=FALSE}
gbm.perf(gbm.fit2, method = "cv")
```
```{r, echo=FALSE, highlight.output = TRUE}
gbm.perf(gbm.fit2, method = "cv")
title("GBM Preformance")
```
---

#Economic Freedom (Multiple Models)
```{r}
hyper_grid <- expand.grid(shrinkage = c(.01, .1, .3),
                          interaction.depth = c(1, 2, 3),
                          n.minobsinnode = c(5, 10, 15),
                          bag.fraction = c(.65, .8, 1), 
                          optimal_trees = 0,min_RMSE = 0)

#for(i in 1:nrow(hyper_grid)) {
#  
#  # train model
#  gbm.tune <- gbm(formula = ECONOMIC.FREEDOM ~ ., distribution = "gaussian",
#                  data = free_train, n.trees = 2500,
#                  interaction.depth = hyper_grid$interaction.depth[i],
#                  shrinkage = hyper_grid$shrinkage[i],
#                  n.minobsinnode = hyper_grid$n.minobsinnode[i],
#                  bag.fraction = hyper_grid$bag.fraction[i],
#                  train.fraction = .75)
  
  # add min training error and trees to grid
#  hyper_grid$optimal_trees[i] <- which.min(gbm.tune$valid.error)
#  hyper_grid$min_RMSE[i] <- sqrt(min(gbm.tune$valid.error))
  
#}
```
---

#Economic Freedom (Multiple Models cont.)

```{r}
#hyper_grid %>% 
#  dplyr::arrange(min_RMSE) %>%
#  head(10)


```

---

#Economic Freedom (Best Model)

```{r,highlight.output = TRUE}
gbm.fit.final <- gbm(formula = ECONOMIC.FREEDOM ~ ., distribution = "gaussian", 
                     data = free_train, n.trees = 4960, interaction.depth = 1, 
                     shrinkage = 0.3, n.minobsinnode = 15, bag.fraction = 1)

# Predictions and RMSE
pred <- predict(gbm.fit.final, n.trees = gbm.fit.final$n.trees, free_test)
caret::RMSE(pred, free_test$ECONOMIC.FREEDOM)
```
---

#Economic Freedom(Best Model cont.)
.pull-left[
```{r, eval=FALSE}
fit_sum <- summary(gbm.fit.final)
```
```{r, echo=FALSE}
fit_sum <- summary(gbm.fit.final)
title("Variable Relevance")
```
]
.pull-right[
```{r}
head(data.frame(fit_sum$var, 
                fit_sum$rel.inf),10)

```
]




